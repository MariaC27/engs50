/* indexer5.c --- 
 * 
 * 
 * Author: Miles B. Hudgins
 * Created: Mon Feb 13 13:30:02 2023 (-0500)
 * Version: 1.0
 * 
 * Description: 
 * 
 */
#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <webpage.h>
#include <pageio.h>
#include <ctype.h>
#include <hash.h>
#include <queue.h>


static int word_total;

typedef struct wordcount{
	char *word_data;
	queue_t *q;
}wordcount_t;

typedef struct qentry{
	int id;
	int count;
}qentry_t;

//MALLOC a new wordcount, give it word_data and give it a new queue, return a pointer to the structure
wordcount_t *new_wordcount(char *word){
	wordcount_t *w = malloc(sizeof(wordcount_t));
	//w->word_data = "";
	//strcpy(w->word_data, word);
	w->word_data = word;
	w->q = qopen();
	return w;
}

//MALLOC a new entry, specify values, place it into the queue
int put_entry(queue_t *queue_toput, int eyedee, int cnt){
	qentry_t *entry = malloc(sizeof(qentry_t));
	entry->id = eyedee;
	entry->count = cnt;
	int result = qput(queue_toput, (void*)entry);
	return result;
}

//takes in a wordcount structure and closes the queue stored inside of it. used for happly()!!!!!
void close_wordcount_queue(void *w){
	wordcount_t *hehehe = w;
	qclose(hehehe->q);
}

bool docsearch(void* entry, const void *keyp){
	qentry_t *e = entry;

	if(e->id == *(int*)keyp)
		return true;//if equal
	return false;//if not equal
}

//search function for hsearch
bool wordsearch(void* elementp, const void* searchkeyp){
	wordcount_t* word_element = elementp;
	if(!strcmp(word_element->word_data, searchkeyp)) 
		return true;
	return false;
}

/*void increase_wordcount(wordcount_t *word){ // function to increase word count per iteration
	word->count++;
	}*/

/*void increase_word_total(void *ep){ // apply to all functions to get total count of all word iterations
	wordcount_t *temp = ep;
	word_total += temp->count;
	}*/

void del_hash_word(void* data){ // this function tries to free up word_data pointer and tmp for every element
	wordcount_t *tmp = data;
	free(tmp->word_data);
	free(tmp);
}

static int normalize_word(char *word){
	if (!(strlen(word) <= 2)){
		for(int i =0; i < strlen(word); i ++){
			char curr = word[i];
			if(!isalpha(curr))
				return 1;
			word[i]=tolower(curr);
		}
		return 0;
	}
	return 1;
}

int main(void){
	
	hashtable_t *h1 = hopen(1000);
	int doc_id = 1;//number that designates the document id to be loaded
	webpage_t* page1 = pageload(doc_id, "../pages/");

	char *path = "./testout.txt";
	FILE *out;
	if((out = fopen(path, "w")) == NULL){printf("Could not open file."); exit(EXIT_FAILURE);}

	int pos = 0;
	char *word;
	while((pos = webpage_getNextWord(page1, pos, &word)) > 0){
		if(normalize_word(word)==0){ // Normalize word here
			wordcount_t *found_word = hsearch(h1, wordsearch, (void *)word, strlen(word)); // hash search
			fprintf(out, "%s\n", word); // print to file
			printf("%s\n", word);
			if(found_word == NULL){//NOT FOUND IN HASH TABLE
				printf("word not found in hash table\n");
				//tmp->word_data = malloc(strlen(word)+1);    
				char *tempword = malloc(strlen(word+1));
				//printf("1\n");
				wordcount_t *tmp = new_wordcount(tempword);
				//printf("2\n");
				//(wordcount_t *)malloc(sizeof(wordcount_t)); // malloc struct
				//strcpy(tmp->word_data, word);
				//tmp->count = 1;
				printf("qput result: %i\n", put_entry(tmp->q, doc_id, 1));//go into the queue in tmp, and place a new entry into it with the doc_d and count 1
				//printf("3\n");
				hput(h1, (void *)tmp, (void *)word, strlen(word));//put tmp into the has table
				//printf("4\n");
			}
			else{//FOUND IN HASH TABLE
				printf("\n\nword found in hash table\n\n\n");
				//found_word->count++; // if duplicate -->> increase word count
				qentry_t *found_entry = qsearch(found_word->q, docsearch, &doc_id);
				if(found_entry != NULL){
					//printf("found entry, increasing count\n");
					found_entry->count++;
				}
				else{
					printf("entry not found, new entry created");
					printf("qput result: %i\n", put_entry(found_word->q, doc_id, 1));//go into the queue in found entry, and place a new entry into it with the doc_d and count 1
				}
			}
	  }
		free(word); // free second pointer from webpage.c
	}
	
	word_total = 0;
	//happly(h1, increase_word_total); // calculate sum of word iterations
	//printf("Sum word count after hash: %i\n", word_total);
	happly(h1, close_wordcount_queue);
	happly(h1, del_hash_word);
	webpage_delete(page1);
	hclose(h1);
 	fclose(out);
	
	exit(EXIT_SUCCESS);
}
